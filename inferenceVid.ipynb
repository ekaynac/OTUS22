{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\enes_/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-12-14 Python-3.10.4 torch-1.12.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144MiB)\n",
      "\n",
      "Loading D:\\Github\\OTUS22\\UAVweights300\\best.onnx for ONNX Runtime inference...\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom',path=r'D:\\Github\\OTUS22\\UAVweights300\\best.onnx')  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "model.conf = 0.6 # NMS confidence threshold\n",
    "#model.iou = 0.45  # NMS IoU threshold\n",
    "#model.agnostic = False  # NMS class-agnostic\n",
    "#model.multi_label = False  # NMS multiple labels per box\n",
    "#model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "model.max_det = 1  # maximum number of detections per image\n",
    "#model.amp = False  # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video address\n",
    "vid_name = 'F:\\SabitKanatVideolar\\Labellanacakvideolar\\GH010012_Trim.mp4'\n",
    "\n",
    "# Video Capturer\n",
    "cap = cv2.VideoCapture(vid_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBox(img,bbox):\n",
    "    x,y,w,h = tuple(map(int,bbox))\n",
    "    cv2.rectangle(img,(x,y),((x+w),(y+h)),(255,0,255),3,1)\n",
    "    cv2.putText(img, \"Tracking\", (75, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for cv2.rectangle\n",
    "thickness=1\n",
    "color=(0,0,255)\n",
    "\n",
    "# Options for cv2.putText\n",
    "# font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# org\n",
    "org = (50, 50)\n",
    "# font\n",
    "fontScale = 0.5\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTracker(num):\n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[num]\n",
    "\n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create() \n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create() \n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.legacy.TrackerTLD_create() \n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create() \n",
    "    if tracker_type == 'GOTURN':\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "    if tracker_type == 'MOSSE':\n",
    "        tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "    if tracker_type == \"CSRT\":\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "flag=1\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (640,640), interpolation = cv2.INTER_AREA)\n",
    "    if flag:\n",
    "        tracker = createTracker(7)\n",
    "        results = model(frame)\n",
    "        df = results.pandas().xyxy[0]\n",
    "        bbox= [20,10,20,10]\n",
    "        ret = tracker.init(frame, bbox)\n",
    "        flag =0\n",
    "    if ret:\n",
    "        cnt+=1\n",
    "        if cnt == 5:\n",
    "            cnt = 0\n",
    "            results = model(frame)\n",
    "            df = results.pandas().xyxy[0]\n",
    "            if df.size != 0:\n",
    "                frame = cv2.rectangle(frame, (int(df[\"xmin\"]),int(df[\"ymin\"])), (int(df[\"xmax\"]),int(df[\"ymax\"])), color, thickness)\n",
    "                frame = cv2.putText(frame, 'UAV: {}'.format(df[\"confidence\"]), (int(df[\"xmin\"]),int(df[\"ymin\"])), font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "                bbox= (int(df[\"xmin\"]), int(df[\"ymin\"]), int(df[\"xmax\"])- int(df[\"xmin\"]), int(df[\"ymax\"])- int(df[\"ymin\"]))\n",
    "                tracker = createTracker(2)\n",
    "                _ = tracker.init(frame, bbox)\n",
    "        _, bbox = tracker.update(frame)\n",
    "        \n",
    "        try:\n",
    "            drawBox(frame,bbox)\n",
    "        except:\n",
    "            frame = cv2.putText(frame, 'No detection', org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"sex\", frame)\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.84964</td>\n",
       "      <td>160.739685</td>\n",
       "      <td>352.701935</td>\n",
       "      <td>193.952576</td>\n",
       "      <td>0.967069</td>\n",
       "      <td>0</td>\n",
       "      <td>UAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xmin        ymin        xmax        ymax  confidence  class name\n",
       "0  297.84964  160.739685  352.701935  193.952576    0.967069      0  UAV"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c25497626eb387c829d69d77d2a11d4b3d4e6b3e3b316f5a1837374208b5d84c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
